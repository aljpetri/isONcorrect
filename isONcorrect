#! /usr/bin/env python

from __future__ import print_function
import os,sys
import argparse

import errno
from time import time
import itertools

# import math
import re
from modules import correct_seqs, create_augmented_reference, align, help_functions


# print(phred_char_to_val)



def get_seq_to_acc(S):
    seq_to_acc = {}
    for i, (acc, seq, qual) in S.items():
        if seq in seq_to_acc:
            seq_to_acc[seq].append(acc)
        else: 
            seq_to_acc[seq] = []
            seq_to_acc[seq] = [acc]

    unique_seq_to_acc = {seq: acc_list[0] for seq, acc_list in  seq_to_acc.items() if len(acc_list) == 1 } 
    print("Non-converged (unique) sequences left:", len(unique_seq_to_acc))
    return seq_to_acc

def get_seq_to_index(S):
    seq_to_index = {}
    for i, (acc, seq, qual) in S.items():
        if seq in seq_to_index:
            seq_to_index[seq].append(i)
        else: 
            seq_to_index[seq] = []
            seq_to_index[seq] = [i]

    unique_seq_to_index = {seq: acc_list[0] for seq, acc_list in  seq_to_index.items() if len(acc_list) == 1 } 
    print("Non-converged (unique) sequences left:", len(unique_seq_to_index))
    return seq_to_index



def get_exon_boundaries(ref_alignment, block_coverage):
    exon_boundaries = []
    ref_pos = 0
    for i, (b1, b2) in enumerate(zip(block_coverage[:-1],block_coverage[1:])):
        if b1 != b2:
            exon_boundaries.append(ref_pos)
        if ref_alignment[i] != "-":
            ref_pos += 1
    return exon_boundaries

def get_deletion_coordinates(ref_alignment, read_alignment):
    deletion_coordinates = []
    ref_pos = 0
    del_state = False
    cand_deletion = []
    for i, n in enumerate(read_alignment):
        if n == "-":
            del_state = True
            cand_deletion.append(ref_pos)
        elif n != "-":
            del_state = False
            if len(cand_deletion) > 10:
                deletion_coordinates.append(cand_deletion)
            cand_deletion = []

        if ref_alignment[i] != "-":
            ref_pos += 1
    deletion_coordinates = [item for sublist in deletion_coordinates for item in sublist]
    return deletion_coordinates

def main(args):
    start = time()
    reads = { i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(args.fastq, 'r')))}
    # kmer_counter(reads)
    # sys.exit()

    seq_to_index = get_seq_to_index(reads)

    # spoa_corrected = open(args.fastq)  #{ i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(args.fastq, 'r')))}
    isocon_corrected = open(args.fastq, "r") #{ i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(args.fastq, 'r')))}

    stripped = []
    i = 0
    for acc, (seq, qual) in help_functions.readfq(open(args.fastq, 'r')):
        if i > 200:
            break
        stripped.append((acc, seq, qual))
        i += 1
    spoa_cons = open(os.path.join(args.outfolder, "stripped.fastq"), "w")
    for (acc, seq, qual) in stripped:
        spoa_cons.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, seq, "+", qual))
    spoa_cons.close()

    print("Correcting {0} reads.".format(len(reads)))
    start = time()

    for iteration in range(1,2):
        print()
        print("ITERATION", iteration)
        args.iteration = iteration
        
        # # MSA
        # reads = { i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(spoa_corrected.name, "r")))}
        # seq_to_index = get_seq_to_index(reads)
        # ref_file_spoa = os.path.join(args.outfolder, "reference_{0}_spoa.fa".format(iteration))
        # spoa_out_file = os.path.join(args.outfolder, "spoa_out_{0}.fa".format(iteration))
        # reference_seq, msa = create_augmented_reference.run_spoa(spoa_corrected.name, ref_file_spoa, spoa_out_file, "spoa")
        # reference_qual = "".join(["," for i in range(len(reference_seq))]) 
        # partition = {}
        # for seq_aln in msa:
        #     seq = "".join(n for n in seq_aln if n != "-")
        #     partition[seq] = (seq_aln, len(seq_to_index[seq]))

        # corrected_spoa = correct_seqs.msa(reference_seq, partition, seq_to_index)
        # spoa_corrected = open(os.path.join(args.outfolder, "corrected_reads_spoa_{0}.fastq".format(iteration)), "w")
        # for acc in sorted(corrected_spoa):
        #     spoa_corrected.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, corrected_spoa[acc], "+", ","*len(corrected_spoa[acc])))
        # spoa_corrected.close()


        # ISOCON
        reads = { i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(isocon_corrected.name,"r")))}
        seq_to_index = get_seq_to_index(reads)
        ref_file_isocon = os.path.join(args.outfolder, "reference_{0}_isocon.fa".format(iteration))
        isocon_out_file = os.path.join(args.outfolder, "isocon_out_{0}.fa".format(iteration))
        dot_graph_path = os.path.join(args.outfolder, "graph_isocon_{0}.dot".format(iteration))
        # reference_seq, msa = create_augmented_reference.run_spoa(isocon_corrected.name, ref_file_isocon, isocon_out_file, "spoa", dot_graph_path)

        isocon_out_file = os.path.join(args.outfolder, "isocon_out_{0}_affine.fa".format(iteration))
        # reference_seq, msa = create_augmented_reference.run_spoa_affine(isocon_corrected.name, ref_file_isocon, isocon_out_file, "spoa_affine", dot_graph_path)
        # reference_seq_longest_path = create_augmented_reference.longest_path(dot_graph_path)
        # print("spoa_affine:", reference_seq_longest_path)

        # reference_seq, msa = create_augmented_reference.run_spoa_affine_v2_0_3(isocon_corrected.name, ref_file_isocon, isocon_out_file, "spoa_affine_2_0_3", dot_graph_path)
        # reference_seq_longest_path = create_augmented_reference.longest_path(dot_graph_path)
        # print("spoa_affine_2_0_3:", reference_seq_longest_path)

        # reference_seq_true = "GGGGTCAGATGCCCTGTAATGAGCCACAGAAACTTGGGCCCATGGGTAGGTTCCAGGAGAGAGGGGCCTGGAGGGGTCCTCAGCCCTGGGGGATTGGGGTGTCAAGCAACTTCTCTCTCCAGGCTCAGTCCTGCGGTCTGTGGGGAGACCTTCCTGTGGGCGCAGCTGGAGTCAAGGCTTGGGGTCTTGGGGTATGCTTCGCAGACAAAGCAGCTGTGCCAGTCTCCGAGTTCCTGGGACTCTGCCAGATCCAGGGCATCCTGAGCGGGCCCGGCTGGGGTGGGGATGGGGTCCGAGGGC"
        # reference_qual_true = "".join(["+" for i in range(len(reference_seq_true))]) 

        # reference_qual_longest_path = "".join(["+" for i in range(len(reference_seq_longest_path))]) 
        # error_rate_sum, ref_longest_alignment, ref_true_alignment, block_coverage = align.block_align_parasail(reference_seq_true, reference_seq_longest_path, reference_qual_true, reference_qual_longest_path, args)
        # print(ref_longest_alignment)
        # print(ref_true_alignment)
        # print(len([1 for n1,n2 in zip(ref_true_alignment,ref_longest_alignment) if n1 !=n2]) )

        
        reference_seq, msa = create_augmented_reference.run_spoa_convex(spoa_cons.name, ref_file_isocon, isocon_out_file, "spoa_convex", dot_graph_path)
        reference_seq_longest_path = create_augmented_reference.longest_path(dot_graph_path)
        print("spoa_convex:", reference_seq_longest_path)
        print(msa)
        for i in range(len(msa)):
            pieces = [ msa[j][i: i+7] for j in range(len(msa))]
            print(pieces)
            # most_common_k =
            if i > 10:
                break

        sys.exit()

        ref_file = os.path.join(args.outfolder, "spoa_ref.fa")
        r = open(ref_file, "w")
        r.write(">{0}\n{1}\n".format("ref", reference_seq_longest_path))
        r.close()
        # error_rate_sum, ref_longest_alignment, ref_true_alignment, block_coverage = align.block_align_parasail(reference_seq_true, reference_seq_longest_path, reference_qual_true, reference_qual_longest_path, args)
        # print(ref_longest_alignment)
        # print(ref_true_alignment)
        # print(len([1 for n1,n2 in zip(ref_true_alignment,ref_longest_alignment) if n1 !=n2]) )

        # sys.exit()
        # reference_seq_longest_path_botond = create_augmented_reference.longest_path_botond(dot_graph_path)
        # print("botond:", reference_seq_longest_path_botond)
        



        # sys.exit()

        parasail_alignments = align.align_parasail(isocon_corrected.name, reference_seq_longest_path, args)
        # mm2_alignments = align.align_mm2( isocon_corrected.name, reference_seq_longest_path, args)
        # align.align_with_nlmgr(isocon_corrected, reference_seq_longest_path)


        # partition_mm2 = {}
        partition_parasail = {}
        # partition_mm2[reference_seq_longest_path] = (0, reference_seq_longest_path, reference_seq_longest_path, 1)
        partition_parasail["ref"] = (0, reference_seq_longest_path, reference_seq_longest_path, 1)
        # dels_parasail = []
        # dels_mm2 = []
        dels_distr_ref = []
        read_errors = {}
        for j in range(0, len(reads)):
            print(j)
            print(parasail_alignments[j][1], "parasail")
            print(parasail_alignments[j][2], "ref")
            print("".join([str(n) for n in parasail_alignments[j][3]]), "block")

            exon_boundaries_parasail = get_exon_boundaries(parasail_alignments[j][2], parasail_alignments[j][3])
            # print(exon_boundaries)
            # print(mm2_alignments[j][1], "mm2")
            # print(mm2_alignments[j][2], "ref")
            # exon_boundaries_mm2 = get_exon_boundaries(mm2_alignments[j][2], mm2_alignments[j][3])
            # deletion_coordinates_mm2 = get_deletion_coordinates(mm2_alignments[j][2], mm2_alignments[j][1])

            (ins, del_, subs,  aligned_length) = help_functions.get_read_errors(parasail_alignments[j][2], parasail_alignments[j][1], parasail_alignments[j][3])
            # print(ins, del_, subs,  aligned_length)
            # print(exon_boundaries)
            # print(deletion_coordinates_mm2)
            # dels_distr_ref.append(deletion_coordinates_mm2)

            acc, seq, qual = reads[j]
            read_errors[seq] = (ins, del_, subs,  aligned_length)
            # partition_mm2[seq] = (0, mm2_alignments[j][2], mm2_alignments[j][1], len(seq_to_index[seq]))
            partition_parasail[acc] = (0, parasail_alignments[j][2], parasail_alignments[j][1], len(seq_to_index[seq]))
        # dels_distr_ref = [coord for sublist in dels_distr_ref for coord in sublist]

        d_c = open(os.path.join(args.outfolder, "dc.txt"), "w")        
        for item in dels_distr_ref:
            d_c.write("{0}\n".format(item))

        from collections import Counter
        c = Counter(dels_distr_ref)
        print(c)

        ## Column correct

        # corrected_mm2 = correct_seqs.correct_to_consensus(reference_seq_longest_path, partition_mm2, seq_to_index)
        corrected_parasail = correct_seqs.correct_to_consensus(partition_parasail, read_errors, args)
        isocon_corrected = open(os.path.join(args.outfolder, "corrected_reads_parasail_{0}.fastq".format(iteration)), "w")
        isocon_corrected_fa = open(os.path.join(args.outfolder, "corrected_reads_parasail_{0}.fasta".format(iteration)), "w")
        for acc in sorted(corrected_parasail):
            isocon_corrected.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, corrected_parasail[acc], "+", ","*len(corrected_parasail[acc]) ))
            isocon_corrected_fa.write(">{0}\n{1}\n".format(acc, corrected_parasail[acc] ))
        isocon_corrected.close()
        isocon_corrected_fa.close()
        sys.exit()

        # Realign 
        reads = { i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(isocon_corrected.name,"r")))}
        seq_to_index = get_seq_to_index(reads)
        parasail_alignments = align.align_parasail(isocon_corrected.name, reference_seq_longest_path, args)
        partition_parasail = {reference_seq_longest_path : (0, reference_seq_longest_path, reference_seq_longest_path, 1)}
        read_errors = {}
        for j in range(0, len(reads)):
            acc, seq, qual = reads[j]
            partition_parasail[seq] = (0, parasail_alignments[j][2], parasail_alignments[j][1], len(seq_to_index[seq]))
            (ins, del_, subs,  aligned_length) = help_functions.get_read_errors(parasail_alignments[j][2], parasail_alignments[j][1], parasail_alignments[j][3])
            acc, seq, qual = reads[j]
            read_errors[seq] = (ins, del_, subs,  aligned_length)

        corrected_parasail = correct_seqs.correct_to_consensus(reference_seq_longest_path, partition_parasail, seq_to_index, read_errors, args)
        isocon_corrected = open(os.path.join(args.outfolder, "corrected_reads_parasail_second{0}.fastq".format(iteration)), "w")
        isocon_corrected_fa = open(os.path.join(args.outfolder, "corrected_reads_parasail_second{0}.fasta".format(iteration)), "w")
        for acc in sorted(corrected_parasail):
            isocon_corrected.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, corrected_parasail[acc], "+", ","*len(corrected_parasail[acc]) ))
            isocon_corrected_fa.write(">{0}\n{1}\n".format(acc, corrected_parasail[acc] ))
        isocon_corrected.close()
        isocon_corrected_fa.close()
        sys.exit()
        

        # Row Correct

        reads = { i : (acc, seq, qual) for i, (acc, (seq, qual)) in enumerate(help_functions.readfq(open(isocon_corrected.name,"r")))}
        k_count = create_augmented_reference.kmer_counter(reads)


        for j in range(0, len(reads)):
            acc, seq, qual = reads[j]
            read_kmers = [seq[i:i+args.k] for i in range(len(seq)-args.k+1)]
            print( "read{0}:".format(acc), [ k_count[kmer] for kmer in read_kmers])

        sys.exit()

        # EVALUATION
        print("EVALUATION")
        reference_seq_true = "GGGGTCAGATGCCCTGTAATGAGCCACAGAAACTTGGGCCCATGGGTAGGTTCCAGGAGAGAGGGGCCTGGAGGGGTCCTCAGCCCTGGGGGATTGGGGTGTCAAGCAACTTCTCTCTCCAGGCTCAGTCCTGCGGTCTGTGGGGAGACCTTCCTGTGGGCGCAGCTGGAGTCAAGGCTTGGGGTCTTGGGGTATGCTTCGCAGACAAAGCAGCTGTGCCAGTCTCCGAGTTCCTGGGACTCTGCCAGATCCAGGGCATCCTGAGCGGGCCCGGCTGGGGTGGGGATGGGGTCCGAGGGC"
        reference_seq_true_splice = "GGGGTCAGATGCCCTGTAATGAGCCACAGAAACTTGGGCCCATGGGTAGGGTCAAGCAACTTCTCTCTCCAGGCTCAGTCCTGCGGTCTGTGGGGAGACCTTCCTGTGGGCGCAGCTGGAGTCAAGGCTTGGGGTCTTGGGGTATGCTTCCCAGGGCATCCTGAGCGGGCCCGGCTGGGGTGGGGATGGGGTCCGAGGGC"
        parasail_alignments = align.align_parasail(isocon_corrected.name, reference_seq_true, args)
        for j in range(0, len(reads)):
            print(j)
            print(parasail_alignments[j][1], "parasail")
            print(parasail_alignments[j][2], "ref")
            print("".join([str(n) for n in parasail_alignments[j][3]]), "block")
            (ins, del_, subs,  aligned_length) = help_functions.get_read_errors(parasail_alignments[j][2], parasail_alignments[j][1], parasail_alignments[j][3])
            print(ins, del_, subs,  aligned_length) 
        for kmer,cnt in sorted(k_count.items(), key = lambda x: x[1], reverse=True):
            print(kmer, cnt, (kmer in reference_seq_true or kmer in reference_seq_true_splice))

        # sys.exit()


        # isocon_corrected = open(os.path.join(args.outfolder, "corrected_reads_mm2_{0}.fastq".format(iteration)), "w")
        # for acc in sorted(corrected_mm2):
        #     isocon_corrected.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, corrected_mm2[acc], "+", ","*len(corrected_mm2[acc]) ))
        # isocon_corrected.close()
        # sys.exit()

        # read_exon_boundaries = {}
        # partition = {}
        # partition[reference_seq_longest_path] = (0, reference_seq_longest_path, reference_seq_longest_path, 1)
        # for j in range(0, len(reads)):
        #     acc, seq, qual = reads[j]
        #     error_rate_sum, read_alignment, ref_alignment, alignment_ratio, block_coverage = align.block_align_parasail(reference_seq_longest_path, seq, reference_qual_longest_path, qual, args)
        #     print(acc)
        #     print(ref_alignment)
        #     print(read_alignment)
        #     print("".join([str(m) for m in block_coverage]))
        #     # if j == 10:
        #     #     sys.exit()
        #     exon_boundaries = get_exon_boundaries(ref_alignment, block_coverage)
        #     print(exon_boundaries)
        #     # print()


        #     read_exon_boundaries[j] = exon_boundaries
        #     mismatches = len([ 1 for n1, n2 in zip(ref_alignment,read_alignment) if n1 != n2 and n1 != "-" and n2 != "-" ])
        #     matches = len([ 1 for n1, n2 in zip(ref_alignment,read_alignment) if n1 == n2 and n1 != "-"])
        #     indels = len(ref_alignment) - mismatches - matches
        #     # qual_dict[acc] =  [ phred_char_to_val[q] for q in qual]
        #     # block_dict[acc] =  [ phred_char_to_val[q] for q in block_coverage]
        #     partition[seq] = (matches+indels, ref_alignment, read_alignment, len(seq_to_index[seq]))

        # print([len(eb) for eb in read_exon_boundaries.values()])
        # break_point_position_counter = {}
        # for read_id in read_exon_boundaries:
        #     for p in read_exon_boundaries[read_id]:
        #         if p in break_point_position_counter:
        #             break_point_position_counter[p] +=1
        #         else:
        #             break_point_position_counter[p] = 1
        # print(len(break_point_position_counter))



        # isoforms = {}
        # read_acc_to_isoform = {}
        # for read_id in read_exon_boundaries:
        #     v = []
        #     for p in read_exon_boundaries[read_id]:
        #         for eb in  [50, 110, 200, 260]:
        #             if abs(p - eb) <= 10:
        #                 v.append(eb)
        #     iso = tuple(sorted(set(v))) if tuple(sorted(set(v))) else (0,0)
        #     print(iso, read_id)
        #     if iso in isoforms:
        #         isoforms[iso] += 1
        #     else:
        #         isoforms[iso]  = 1
        #     read_acc_to_isoform[read_id] = iso

        # print(isoforms)
        # print(sorted([ (p,c) for p,c in break_point_position_counter.items()]))


        # for iso in isoforms:
        #     iso_file = open(os.path.join(args.outfolder, "isoform_{0}.fastq".format(iso)), "w")
        #     for read_id, read_iso in read_acc_to_isoform.items():
        #         # print(read_acc_to_isoform.keys())
        #         # print(reads.keys())
        #         if read_iso == iso:
        #             acc, seq, qual = reads[read_id]
        #             iso_file.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, seq, "+", qual))


        # sys.exit()

        # corrected_isocon = correct_seqs.correct_to_consensus(reference_seq_longest_path, partition, seq_to_index)

        # partition = {}
        # partition[reference_seq] = (0, reference_seq, reference_seq, 1)
        # for j in range(0, len(reads)):
        #     acc, seq, qual = reads[j]
        #     error_rate_sum, read_alignment, ref_alignment, alignment_ratio, block_coverage = block_align(reference_seq, seq, reference_qual, qual, args)
        #     print(ref_alignment)
        #     print(read_alignment)
        #     print(block_coverage)
        #     print()
        #     # sys.exit()
        #     mismatches = len([ 1 for n1, n2 in zip(ref_alignment,read_alignment) if n1 != n2 and n1 != "-" and n2 != "-" ])
        #     matches = len([ 1 for n1, n2 in zip(ref_alignment,read_alignment) if n1 == n2 and n1 != "-"])
        #     indels = len(ref_alignment) - mismatches - matches
        #     # qual_dict[acc] =  [ phred_char_to_val[q] for q in qual]
        #     # block_dict[acc] =  [ phred_char_to_val[q] for q in block_coverage]
        #     partition[seq] = (matches+indels, ref_alignment, read_alignment, len(seq_to_index[seq]))
        # corrected_isocon = correct_seqs.correct_to_consensus(reference_seq, partition, seq_to_index)

        # isocon_corrected = open(os.path.join(args.outfolder, "corrected_reads_isocon_{0}.fastq".format(iteration)), "w")
        # for acc in sorted(corrected_isocon):
        #     isocon_corrected.write("@{0}\n{1}\n{2}\n{3}\n".format(acc, corrected_isocon[acc], "+", ","*len(corrected_isocon[acc]) ))
        # isocon_corrected.close()
        
        # sys.exit()

    # # correct all seqs w.r.t. origin consensus
    # qual_dict = {"augmented_ref" : [ phred_char_to_val[q] for q in reference_qual] }    
    # # block_dict = {origin_acc : [ 1 for q in origin_qual] }    
    # partition = {}

    # for i in range(0, len(reads)):
    #     acc, seq, qual = reads[i]
    #     error_rate_sum, read_alignment, origin_alignment, alignment_ratio, block_coverage = block_align(reference_seq, seq, reference_qual, qual, args)

    #     mismatches = len([ 1 for n1, n2 in zip(origin_alignment,read_alignment) if n1 != n2 and n1 != "-" and n2 != "-" ])
    #     matches = len([ 1 for n1, n2 in zip(origin_alignment,read_alignment) if n1 == n2 and n1 != "-"])
    #     indels = len(origin_alignment) - mismatches - matches

    #     # print([ phred_char_to_val[q] for q in qual])
    #     qual_dict[acc] =  [ phred_char_to_val[q] for q in qual]
    #     # block_dict[acc] =  [ phred_char_to_val[q] for q in block_coverage]
    #     partition[seq] = (matches+indels, origin_alignment, read_alignment, len(seq_to_acc[seq]))

    # S_prime_partition, S_prime_quality_vector = correct_seqs.correct_to_consensus(reference_seq, partition, seq_to_acc, qual_dict)
    # reads_corrected = open(os.path.join(args.outfolder,"corrected_reads_isocon.fa"), "w")

    # for acc in S_prime_partition:
    #     reads_corrected.write(">{0}\n{1}\n".format(acc, S_prime_partition[acc]))
    # reads_corrected.close()

if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="De novo clustering of long-read transcriptome reads", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument('--version', action='version', version='%(prog)s 0.0.2')

    parser.add_argument('--fastq', type=str,  default=False, help='Path to input fastq file with reads')
    # parser.add_argument('--t', dest="nr_cores", type=int, default=8, help='Number of cores allocated for clustering')

    parser.add_argument('--ont', action="store_true", help='Clustering of ONT transcript reads.')
    parser.add_argument('--isoseq', action="store_true", help='Clustering of PacBio Iso-Seq reads.')

    parser.add_argument('--k', type=int, default=13, help='Kmer size')
    parser.add_argument('--w', type=int, default=20, help='Window size')
    parser.add_argument('--outfolder', type=str,  default=None, help='A fasta file with transcripts that are shared between samples and have perfect illumina support.')
    # parser.add_argument('--pickled_subreads', type=str, help='Path to an already parsed subreads file in pickle format')
    # parser.set_defaults(which='main')
    args = parser.parse_args()

    if args.ont and args.isoseq:
        print("Arguments mutually exclusive, specify either --isoseq or --ont. ")
        sys.exit()
    elif args.isoseq:
        args.k = 15
        args.w = 50
    elif args.ont:
        args.k = 13
        args.w = 20


    if len(sys.argv)==1:
        parser.print_help()
        sys.exit()
    if not args.fastq and not args.flnc and not  args.ccs:
        parser.print_help()
        sys.exit()


    if args.outfolder and not os.path.exists(args.outfolder):
        os.makedirs(args.outfolder)


    # edlib_module = 'edlib'
    parasail_module = 'parasail'
    # if edlib_module not in sys.modules:
    #     print('You have not imported the {0} module. Only performing clustering with mapping, i.e., no alignment.'.format(edlib_module))
    if parasail_module not in sys.modules:
        print('You have not imported the {0} module. Only performing clustering with mapping, i.e., no alignment!'.format(parasail_module))
        sys.exit(1)
    if 100 < args.w or args.w < args.k:
        print('Please specify a window of size larger or equal to k, and smaller than 100.')
        sys.exit(1)

    main(args)

